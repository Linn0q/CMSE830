{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "714d76f4-9e71-4ce9-ba43-494cb6776931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with invalid dates: 2\n",
      "Recommended games:\n",
      "114                                   God of War\n",
      "110                              Hogwarts Legacy\n",
      "33                                    Diablo® IV\n",
      "50                                         Hades\n",
      "4                                     ELDEN RING\n",
      "76                     STAR WARS Jedi: Survivor™\n",
      "109                              DARK SOULS™ III\n",
      "71                                     Lies of P\n",
      "81                               Sonic Frontiers\n",
      "48     Sekiro™: Shadows Die Twice - GOTY Edition\n",
      "Name: name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import ast\n",
    "\n",
    "# Read the data\n",
    "df = pd.read_csv('steam5.csv')\n",
    "\n",
    "# Data Cleaning\n",
    "\n",
    "# Parse 'genres', 'developer', 'publisher' fields\n",
    "df['genres'] = df['genres'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else [])\n",
    "df['developer'] = df['developer'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else [])\n",
    "df['publisher'] = df['publisher'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else [])\n",
    "\n",
    "# Clean 'number_of_reviews_from_purchased_people' and 'number_of_english_reviews' to numeric\n",
    "def clean_number(x):\n",
    "    if isinstance(x, str):\n",
    "        x = x.replace(',', '').replace('(', '').replace(')', '').strip()\n",
    "        return int(x) if x.isdigit() else np.nan\n",
    "    return np.nan\n",
    "\n",
    "df['number_of_reviews_from_purchased_people'] = df['number_of_reviews_from_purchased_people'].apply(clean_number)\n",
    "df['number_of_english_reviews'] = df['number_of_english_reviews'].apply(clean_number)\n",
    "\n",
    "# Clean 'release_date' column\n",
    "def clean_date(date_str):\n",
    "    try:\n",
    "        # Attempt parsing with different formats\n",
    "        return pd.to_datetime(date_str, format='%d %b, %Y', errors='coerce') or \\\n",
    "               pd.to_datetime(date_str, format='%b %Y', errors='coerce') or \\\n",
    "               pd.to_datetime(date_str, errors='coerce')\n",
    "    except Exception:\n",
    "        return pd.NaT\n",
    "\n",
    "df['release_date'] = df['release_date'].apply(clean_date)\n",
    "\n",
    "# Check for invalid dates\n",
    "invalid_dates = df[df['release_date'].isna()]\n",
    "print(f\"Rows with invalid dates: {len(invalid_dates)}\")\n",
    "\n",
    "# Map 'overall_player_rating' to numeric scores\n",
    "rating_map = {\n",
    "    'Overwhelmingly Positive': 7,\n",
    "    'Very Positive': 6,\n",
    "    'Positive': 5,\n",
    "    'Mostly Positive': 5,\n",
    "    'Mixed': 4,\n",
    "    'Negative': 3,\n",
    "    'Mostly Negative': 3,\n",
    "    'Very Negative': 2,\n",
    "    'Overwhelmingly Negative': 1\n",
    "}\n",
    "df['player_rating_score'] = df['overall_player_rating'].map(rating_map)\n",
    "df['player_rating_score'] = df['player_rating_score'].fillna(df['player_rating_score'].median())\n",
    "\n",
    "# Create 'combined_features' for each game\n",
    "def combine_features(row):\n",
    "    genres = ' '.join(row['genres'])\n",
    "    developers = ' '.join(row['developer'])\n",
    "    publishers = ' '.join(row['publisher'])\n",
    "    description = row['short_description']\n",
    "    return f\"{genres} {developers} {publishers} {description}\"\n",
    "\n",
    "df['combined_features'] = df.apply(combine_features, axis=1)\n",
    "\n",
    "# Create the TF-IDF matrix\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = tfidf.fit_transform(df['combined_features'])\n",
    "\n",
    "# Compute cosine similarity\n",
    "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "# Create reverse mapping of game titles to indices\n",
    "indices = pd.Series(df.index, index=df['name']).drop_duplicates()\n",
    "\n",
    "# Function to get recommendations\n",
    "def get_recommendations(name, cosine_sim=cosine_sim):\n",
    "    if name not in indices:\n",
    "        return f\"Game '{name}' not found in dataset.\"\n",
    "    idx = indices[name]\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:11]  # Exclude the first one (itself), get top 10\n",
    "    game_indices = [i[0] for i in sim_scores]\n",
    "    return df['name'].iloc[game_indices]\n",
    "\n",
    "# Example usage\n",
    "recommended_games = get_recommendations('Black Myth: Wukong')\n",
    "print(\"Recommended games:\")\n",
    "print(recommended_games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "49e8e48d-24c0-46f1-8f9b-13989762207f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number_of_reviews_from_purchased_people      int64\n",
      "number_of_english_reviews                    int64\n",
      "player_rating_encoded                        int32\n",
      "1980s                                        int64\n",
      "1990's                                       int64\n",
      "                                            ...   \n",
      "you                                        float64\n",
      "your                                       float64\n",
      "yours                                      float64\n",
      "yourself                                   float64\n",
      "zombies                                    float64\n",
      "Length: 853, dtype: object\n",
      "Mean Squared Error: 3.54\n",
      "Games recommended for 'Black Myth: Wukong':\n",
      "['NARAKA: BLADEPOINT', 'Russian Fishing 4', 'Shawarma Legend', 'Downhill Pro Racer', 'PUBG: BATTLEGROUNDS']\n",
      "Predicted rating for 'Black Myth: Wukong':\n",
      "Overwhelmingly Positive\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import ast\n",
    "import re\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import NearestNeighbors, KNeighborsRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('steam5.csv')\n",
    "\n",
    "# Step 1: Data Cleaning\n",
    "\n",
    "# Parse genres and other list-like columns\n",
    "def parse_list_column(column):\n",
    "    return column.apply(lambda x: ast.literal_eval(x) if pd.notnull(x) else [])\n",
    "\n",
    "df['genres'] = parse_list_column(df['genres'])\n",
    "\n",
    "# Clean review count columns\n",
    "def clean_review_count(value):\n",
    "    if pd.isnull(value):\n",
    "        return 0\n",
    "    # Extract only numeric parts from the string\n",
    "    numeric_part = re.findall(r'\\d+', value.replace(',', ''))\n",
    "    if numeric_part:\n",
    "        return sum(map(int, numeric_part))\n",
    "    return 0\n",
    "\n",
    "df['number_of_reviews_from_purchased_people'] = df['number_of_reviews_from_purchased_people'].apply(clean_review_count)\n",
    "df['number_of_english_reviews'] = df['number_of_english_reviews'].apply(clean_review_count)\n",
    "\n",
    "# Parse release date\n",
    "def parse_release_date(date_str):\n",
    "    try:\n",
    "        return datetime.strptime(date_str, '%d %b, %Y')\n",
    "    except ValueError:\n",
    "        try:\n",
    "            return datetime.strptime(date_str, '%b %Y')\n",
    "        except ValueError:\n",
    "            return pd.NaT\n",
    "\n",
    "df['release_date'] = df['release_date'].apply(parse_release_date)\n",
    "\n",
    "# Drop rows with missing values for essential columns\n",
    "df = df.dropna(subset=['release_date', 'overall_player_rating'])\n",
    "\n",
    "# Step 2: Feature Engineering\n",
    "\n",
    "# One-Hot Encode genres\n",
    "genres_dummies = df['genres'].str.join('|').str.get_dummies()\n",
    "\n",
    "# Label Encode overall_player_rating\n",
    "rating_le = LabelEncoder()\n",
    "df['player_rating_encoded'] = rating_le.fit_transform(df['overall_player_rating'])\n",
    "\n",
    "# Combine descriptions for TF-IDF vectorization\n",
    "df['combined_description'] = df['short_description'] + ' ' + df['long_description']\n",
    "\n",
    "# TF-IDF Vectorization\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=500)\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df['combined_description'])\n",
    "\n",
    "# Create DataFrame from TF-IDF matrix\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
    "\n",
    "# Combine all features\n",
    "features_df = pd.concat([\n",
    "    df[['number_of_reviews_from_purchased_people', 'number_of_english_reviews', 'player_rating_encoded']],\n",
    "    genres_dummies,\n",
    "    tfidf_df\n",
    "], axis=1)\n",
    "\n",
    "# Replace NaN values with 0\n",
    "features_df = features_df.fillna(0)\n",
    "\n",
    "# Ensure all features are numeric\n",
    "print(features_df.dtypes)\n",
    "\n",
    "# Step 3: KNN Modeling\n",
    "\n",
    "# Initialize and fit NearestNeighbors model\n",
    "nn_model = NearestNeighbors(metric='cosine', algorithm='brute')\n",
    "nn_model.fit(features_df)\n",
    "\n",
    "# KNN Recommendation Function\n",
    "def recommend_games(game_name, n_recommendations=5):\n",
    "    try:\n",
    "        game_index = df[df['name'] == game_name].index[0]\n",
    "        game_features = features_df.iloc[game_index].values.reshape(1, -1)\n",
    "        # Ensure the input for NearestNeighbors has valid feature names\n",
    "        game_features = pd.DataFrame(game_features, columns=features_df.columns)\n",
    "        distances, indices = nn_model.kneighbors(game_features, n_neighbors=n_recommendations+1)\n",
    "        recommended_games = df.iloc[indices[0][1:]]['name']\n",
    "        return recommended_games.tolist()\n",
    "    except IndexError:\n",
    "        return \"Game not found in the dataset.\"\n",
    "\n",
    "# Split data for KNN Regressor\n",
    "X = features_df\n",
    "y = df['player_rating_encoded']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and fit KNeighborsRegressor\n",
    "knn_regressor = KNeighborsRegressor(n_neighbors=5)\n",
    "knn_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Predict ratings for the test set\n",
    "y_pred = knn_regressor.predict(X_test)\n",
    "\n",
    "# Calculate Mean Squared Error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "\n",
    "# Rating Prediction Function\n",
    "def predict_rating(game_name):\n",
    "    try:\n",
    "        game_index = df[df['name'] == game_name].index[0]\n",
    "        game_features = features_df.iloc[game_index].values.reshape(1, -1)\n",
    "        # Ensure the input for KNeighborsRegressor has valid feature names\n",
    "        game_features = pd.DataFrame(game_features, columns=features_df.columns)\n",
    "        predicted_rating = knn_regressor.predict(game_features)\n",
    "        rating_label = rating_le.inverse_transform([int(round(predicted_rating[0]))])[0]\n",
    "        return rating_label\n",
    "    except IndexError:\n",
    "        return \"Game not found in the dataset.\"\n",
    "\n",
    "# Example Usage\n",
    "# Recommend games\n",
    "game_name = 'Black Myth: Wukong'\n",
    "print(f\"Games recommended for '{game_name}':\")\n",
    "print(recommend_games(game_name))\n",
    "\n",
    "# Predict rating\n",
    "print(f\"Predicted rating for '{game_name}':\")\n",
    "print(predict_rating(game_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4fdcdc5c-f2e8-459b-936a-a604c12a9822",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 28\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m column\u001b[38;5;241m.\u001b[39mapply(safe_parse)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# 应用清洗函数到嵌套字段\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenres\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m parse_list_column(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenres\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     29\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminimum_system_requirement\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m parse_list_column(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminimum_system_requirement\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     30\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecommend_system_requirement\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m parse_list_column(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecommend_system_requirement\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "Cell \u001b[1;32mIn[36], line 25\u001b[0m, in \u001b[0;36mparse_list_column\u001b[1;34m(column)\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mSyntaxError\u001b[39;00m):\n\u001b[0;32m     24\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m []\n\u001b[1;32m---> 25\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m column\u001b[38;5;241m.\u001b[39mapply(safe_parse)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4800\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SeriesApply(\n\u001b[0;32m   4918\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4919\u001b[0m         func,\n\u001b[0;32m   4920\u001b[0m         convert_dtype\u001b[38;5;241m=\u001b[39mconvert_dtype,\n\u001b[0;32m   4921\u001b[0m         by_row\u001b[38;5;241m=\u001b[39mby_row,\n\u001b[0;32m   4922\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[0;32m   4923\u001b[0m         kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m-> 4924\u001b[0m     )\u001b[38;5;241m.\u001b[39mapply()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[0;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[0;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[0;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[0;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_map_values(\n\u001b[0;32m   1508\u001b[0m     mapper\u001b[38;5;241m=\u001b[39mcurried, na_action\u001b[38;5;241m=\u001b[39maction, convert\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_dtype\n\u001b[0;32m   1509\u001b[0m )\n\u001b[0;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[1;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m algorithms\u001b[38;5;241m.\u001b[39mmap_array(arr, mapper, na_action\u001b[38;5;241m=\u001b[39mna_action, convert\u001b[38;5;241m=\u001b[39mconvert)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer(values, mapper, convert\u001b[38;5;241m=\u001b[39mconvert)\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[0;32m   1747\u001b[0m     )\n",
      "File \u001b[1;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[36], line 19\u001b[0m, in \u001b[0;36mparse_list_column.<locals>.safe_parse\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msafe_parse\u001b[39m(x):\n\u001b[1;32m---> 19\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pd\u001b[38;5;241m.\u001b[39misnull(x):  \u001b[38;5;66;03m# 处理缺失值\u001b[39;00m\n\u001b[0;32m     20\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m []\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "# 导入必要的库\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "\n",
    "# 数据清洗\n",
    "def parse_list_column(column):\n",
    "    \"\"\"安全解析嵌套字符串字段\"\"\"\n",
    "    def safe_parse(x):\n",
    "        if pd.isnull(x):  # 处理缺失值\n",
    "            return []\n",
    "        try:\n",
    "            return ast.literal_eval(x) if isinstance(x, str) else x\n",
    "        except (ValueError, SyntaxError):\n",
    "            return []\n",
    "    return column.apply(safe_parse)\n",
    "\n",
    "# 应用清洗函数到嵌套字段\n",
    "df['genres'] = parse_list_column(df['genres'])\n",
    "df['minimum_system_requirement'] = parse_list_column(df['minimum_system_requirement'])\n",
    "df['recommend_system_requirement'] = parse_list_column(df['recommend_system_requirement'])\n",
    "df['developer'] = parse_list_column(df['developer'])\n",
    "df['publisher'] = parse_list_column(df['publisher'])\n",
    "\n",
    "# 转换评价数量为数值\n",
    "def parse_review_number(s):\n",
    "    if pd.isnull(s):\n",
    "        return 0\n",
    "    s = ''.join(filter(str.isdigit, str(s)))  # 提取数字\n",
    "    return int(s) if s else 0\n",
    "\n",
    "df['number_of_reviews_from_purchased_people'] = df['number_of_reviews_from_purchased_people'].apply(parse_review_number)\n",
    "df['number_of_english_reviews'] = df['number_of_english_reviews'].apply(parse_review_number)\n",
    "\n",
    "# 格式化发布日期\n",
    "def parse_date(date_str):\n",
    "    try:\n",
    "        return datetime.strptime(date_str, '%d %b, %Y')\n",
    "    except:\n",
    "        return pd.NaT\n",
    "\n",
    "df['release_date'] = df['release_date'].apply(parse_date)\n",
    "df['release_date'] = df['release_date'].fillna(df['release_date'].median())  # 填充缺失值\n",
    "\n",
    "# 特征工程\n",
    "# 编码类别特征\n",
    "mlb = MultiLabelBinarizer()\n",
    "genres_encoded = mlb.fit_transform(df['genres'])\n",
    "genres_df = pd.DataFrame(genres_encoded, columns=mlb.classes_)\n",
    "\n",
    "# 编码玩家评价\n",
    "rating_mapping = {\n",
    "    'Overwhelmingly Positive': 5,\n",
    "    'Very Positive': 4,\n",
    "    'Positive': 3,\n",
    "    'Mixed': 2,\n",
    "    'Negative': 1,\n",
    "    'Very Negative': 0\n",
    "}\n",
    "df['overall_player_rating'] = df['overall_player_rating'].map(rating_mapping).fillna(0)\n",
    "\n",
    "# 文本特征提取\n",
    "tfidf = TfidfVectorizer(max_features=1000)\n",
    "description_tfidf = tfidf.fit_transform(df['short_description'].fillna(''))\n",
    "\n",
    "# 构建特征矩阵\n",
    "features = np.hstack([\n",
    "    description_tfidf.toarray(),\n",
    "    df[['number_of_reviews_from_purchased_people', 'number_of_english_reviews']].values,\n",
    "    genres_encoded\n",
    "])\n",
    "\n",
    "# 标签\n",
    "labels = df['overall_player_rating'].values\n",
    "\n",
    "# 数据集划分\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# 模型训练\n",
    "svm_classifier = SVC(kernel='linear')\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "# 模型预测\n",
    "y_pred = svm_classifier.predict(X_test)\n",
    "\n",
    "# 结果评估\n",
    "print(\"分类模型评估结果：\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# 游戏推荐（基于内容的推荐）\n",
    "def recommend_games(game_name, top_n=5):\n",
    "    if game_name not in df['name'].values:\n",
    "        print(f\"游戏 {game_name} 不在数据集中。\")\n",
    "        return []\n",
    "    idx = df.index[df['name'] == game_name][0]\n",
    "    game_vector = features[idx].reshape(1, -1)\n",
    "    similarities = cosine_similarity(game_vector, features)\n",
    "    similar_indices = similarities[0].argsort()[-top_n-1:-1][::-1]\n",
    "    recommended_games = df.iloc[similar_indices]['name'].values\n",
    "    return recommended_games\n",
    "\n",
    "# 示例：推荐与 \"Black Myth: Wukong\" 相似的游戏\n",
    "recommended = recommend_games(\"Black Myth: Wukong\")\n",
    "print(\"推荐的游戏：\", recommended)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
